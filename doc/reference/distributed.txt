==================
Distributed AMUSE
==================

It is possible to run AMUSE on multiple machines simultaneously. The AMUSE script itself aways runs on a users' local machine, while workers for codes can be "send out" to remote machines such as workstations, clusters, etc.


Installation
------------

Deploying workers one remote machines requires a full installation of AMUSE on each machine. For each code "sockets" support needs to be present. This is done by default, and should be available for all codes. Note that older versions of Fortran lack the necessary features to support sockets workers.

On each machine, the distributed code also needs to be build. Distributed AMUSE requires a Java Development Kit (JDK), preferably Oracle Java version 7. The ``configure`` script tries to locate the JDK, but you may need to specify it by hand. For details, see:

.. code-block:: sh

	> ./configure --help

To build distributed amuse run the following at the amuse root:
	
.. code-block:: sh

	> make distributed.code

To check if the installation is set-up properly, run all the tests related to the worker interface:

.. code-block:: sh

	> cd $AMUSE_DIR
	> nosetests -v test/codes_tests/test*implementation.py
	
Note that Distributed AMUSE is mostly tested with the version of MPI includes in the amuse "prerequisites". If you get MPI errors while running remote (parallel) workers, try using the install.py script included in AMUSE to install the prerequisites.  

Overview
-----------

Usage of Distributed Amuse is (by design) very close to the usage of any other code in AMUSE. The main difference being it contains resources, pilots, and jobs, instead of particles.

TODO: add overview image(s)

Resource
	Description of a machine capable of running jobs. For each resource distributed AMUSE will launch a support process (HUB) to facilitate communication and coordination between the workers and AMUSE
	
Pilot
	Process running on a resource (often within a reservation on a resource) waiting for jobs to run on behalf of AMUSE. Can consist of multiple machines.
	
Job
	Worker process. Will search for a suitable pilot to run on.

In general, a user will first define resources, then deploy pilots on these resources, and finally create codes that make use of the machines offered by the pilots.


Initializing the Distributed AMUSE code
---------------------------------------

Distributed Amuse can be initialized like any other code:

    >>> from amuse.community.distributed.interface import DistributedAmuseInterface, DistributedAmuse
    >>> from amuse.community.distributed.interface import Resource, Resources, Pilot, Pilots
    >>> 
    >>> #initialize code, print output of code to console
    >>> instance = DistributedAmuse(redirection='none')


Parameters
----------

Distributed AMUSE supports a few parameters to adjust settings. All parameters need to be set before any resource, pilot or job is made to have effect.

Overview of settings:

debug
	Boolean parameters, defaults to False. If true/enabled, will output additional debugging information and logs, both in the code output, and in a `distributed-amuse-logs` folder on any target machine used.
webinterface_port
	Port on which a simple webinterface is available for monitoring. Defaults to "0", for a port determined automatically.
start_hubs
	To facilitate communication across different networks (with for instance firewalls), as hub is by default started on  
	
    >>> instance.parameters.debug = True
    >>> instance.parameters.webinterface_port = 5555
    >>> instance.commit_parameters()
    >>>
    >>> print instance.parameters.webinterface_port
    

Monitoring
----------

Distributed Amuse has a small build-in webinterface for monitoring. A utility function is available to get the url:

    >>> import webbrowser
    >>>
    >>> webbrowser.open(instance.get_webinterface_url())

Specifying resources
--------------------

In order to use a remote machine, AMUSE needs to have some information about this resource such as the host name, type of machine, username to gain access, etc.
This can be specified by creating a "Resource" in Distributed AMUSE:

    >>> resource = Resource()
    >>> resource.name = "some.resource"
    >>> resource.location = "user@machine.example.com"
    >>> resource.scheduler = "ssh"
    >>> resource.amuse_dir = "/home/user/amuse"
    >>>
    >>> instance.resources.add_resource(resource)




